# 適応クエリ実行(Adaptive Query Execution)

Sparkは最適な処理実行プランを作るためにコストベースの最適化を行なっています。この最適化には処理実行を開始する前に利用可能な統計情報、例えばそのテーブルの行の数、カラムのユニーク値の個数、Null値、最小・最大数などを使用します。これよって、結合(JOIN)の方式をソートマージ結合よりも高速に実施可能なブロードキャストハッシュ結合に変更するなどの最適化を行なっています。ただし、最大最適化に必要な統計値(カーディナリティやある時点でのパーティションのサイズなど)は全ては処理事前にはわかっていません。そのため、これらの値は推定や経験則による想定値が使用されています。

そこで、実行プランを処理している最中にこれらの統計値を取得して、実行プランを再度最適化する方式が導入されました。これがAdaptive Query Execution(適応クエリ実行, AQE)です。AQEでは特に以下の4つのパフォーマンス劣化要因の最適化を実施します。

## 動的なシャッフルパーティションの結合(Dynamically coalescing shuffle partitions)

Sparkではデータをシャッフルパーティションという細かいデータに分割し、クラスタネットワーク上で分散的に演算処理を実施していきます。
このとき、一つのシャッフルパーティションのデータサイズが大き過ぎる場合、メモリ上からデータが溢れてしまい(Spill)、パフォーマンスが劣化します。逆にサイズが小さ過ぎる場合、パーティション数が増加するため、シャッフルに関わるネットワークコストが高くなり、やはりパフォーマンスが劣化します。そのため、シャッフルパーティションのサイズと数は適度な値に保つ必要があります。ただし、このパーティションサイズは実行時になって初めて分かる値のため、実行前の実行プラン作成時には決定できません。

AQEでは、実行中にこのパーティションサイズをその時に使える統計情報を元に実行プランを再最適化することを行います。この中で、細かく分割しすぐたシャッフルパーティションを結合させる機能が動的なシャッフルパーティションの結合(Dynamically coalescing shuffle partitions)です。


## 動的な結合方式の切り替え(Dynamically switching join strategies)

テーブル通しの結合処理(JOIN)も、テーブルサイズによって最適な方式が異なります。もし片方のテーブルサイズが小さい場合、そのテーブルを全てのExecutorにブロードキャストすることで、ソートとその後のパーティションのシャッフルを回避できるため、効率よく結合処理ができます。この方式をブロードキャストハッシュ結合と呼びます。

ただし、この場合もこの結合するテーブルのいずれかのサイズが大きい場合、データのブロードキャスのコストた高くなり、また、Executor上でのSpillが発生するため、逆にソート・マージ結合に比べてパフォーマンスが劣化します。
事前の実行プランでは決定的ではないため、最適な方式を選択するのが難しい問題がありました。

AQEでは、実行中にテーブルサイズによってこの結合方式を動的に変える再最適化を行ないます。これが動的な結合方式の切り替え(Dynamically switching join strategies)です。


## 動的な結合時スキューの緩和(Dynamically optimizing skew joins)

Sparkにおいて、データの偏り(Skew)もパフォーマンスを劣化させる主な要因の一つです。
AQEではテーブルの結合のときに、あるパーティションだけ大きく偏っている場合、このパーティションを分割することでSkewを回避する再最適化を実施します。これを動的な結合時スキューの緩和(Dynamically optimizing skew joins)と呼びます。


## AQEのパフィーマンス向上

それでは、AQEが有効になることでどの程度パフォーマンスが向上するのでしょうか。もちろんクエリの種類によって効果が異なります。一つのレポート(Databricks社のブログ記事, https://www.databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html )によると、TPC-DSのベンチマーククエリから10クエリをピックアップして計測したところ差が大きかったもので8倍、小さいものでも1.1倍の速度向上が確認できています。