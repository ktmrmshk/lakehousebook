# Lakehouse book - from CSV to レイクハウス

## はじめに

この本を手に取った方であれば、仕事や趣味などで「データを扱う」ということを何かしらされている場合が多いと思います。いやいや、そもそも一般に生きていれば「データ」は溢れているし、「データ」に触れないで、意識しているかしていないかを除けば、完全に「データ」から逃れて生活することは難しいと思います。例えば、出かけるときに服装や持ち物をどうしようかと「天気予報」を見て決めるし、晴れの天気予報だけど最近は朝晴れている場合、職場の周りは夕立が多く、折り畳み傘を持って行った方がいい、などというわけです。ここでは、「天気予報」に加えて、今までの経験値が「データ」として予測に使われているわけです。

ということで、「データを扱う」というのは、もはや壮大なテーマであり、一概にこういう方法やツールで完全に対応できるという話ではないわけです。ではどうするかというと、「データを扱う」人が適切に考えて、管理し、操作することが唯一の解なのかなと思います。その意味で、ここでは、特に現在のITシステムやAI(人工知能)周りで問題になりやすい3Vな「データ」を扱うプラクティスを実際に体感しながら、「データを扱う上での勘所が感覚として解る」というのを目標に話を進めていきたいと思います。

私も含め、一般の人間は最初に頭で考えるよりも、まずは、体感して、感覚的に身につけ、それから頭を使って汎化し、一般化知識にしていく、というのがうまくいくことが多いと思い気がします。その立場で、テキスト上の数値データであるCSVファイルから初めて、昨今新しいデータアーキテクチャである「レイクハウス」を理解するところまでを見ていきます。

「レイクハウス」はデータを効率的・効果的に扱うためのプラクティスから生まれた「考え方」であり、何かのツールやベンダ固有の製品・サービスではありません。そのため、ここで目標にしている「体感的にわかる」状態になれば、皆さんの好きなツールやサービスで実現・構成することが可能です。ただし、具体例がないと「体感的に」分かりづらい部分がありますので、今回の説明では、以下のオープンソースのフレームワークを使用します。プレーンなLinux環境から始めて、実際のコードも載せますので、実行しながら体感してください。

* 計算機(+物理ストレージ): Linux (Ubuntu) (+ローカルディスク)
* 処理エンジン: Apache Spark
* ストレージエンジン: Deltalake

それでは、早速いきましょう。

## データを扱う



## テーブルデータとCSV
## データベース
## データレイク
## スキーマ on read
## データ更新とデータベース
## データ更新とストレージレイヤ
## ストレージとコンピュートの分離
## レイクハウスとDelta Lake
## ガバナンスとメタデータ管理